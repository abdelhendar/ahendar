{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df2 = pd.read_excel('Data/data.xlsx', sheet_name='Mesures', header=1)\n",
    "    df2.drop(index=0, inplace=True)\n",
    "\n",
    "    df1 = pd.read_excel('Data/Raw_data_from26.10to09.11.2022.xlsx', sheet_name='Mesures', header=1)\n",
    "    df1.drop(index=0, inplace=True)\n",
    "\n",
    "    df = pd.concat([df1.iloc[:-41], df2], axis=0)\n",
    "    df.set_index(pd.to_datetime(df['Date']+' '+df['Heure'], format=\"%d/%m/%Y %H:%M:%S\"), inplace=True)\n",
    "\n",
    "    df.to_pickle('Data/df.pkl')\n",
    "\n",
    "df = pd.read_pickle('Data/df.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['business_day'] = np.is_busday(df.index.round('1D').values.astype('datetime64[D]'))\n",
    "\n",
    "feat = 'PT (1 min)'\n",
    "df[f'{feat}_q1'] = df[feat].rolling(60).quantile(.25)\n",
    "df[f'{feat}_q3'] = df[feat].rolling(60).quantile(.75)\n",
    "df[f'{feat}_mean'] = df[feat].rolling(120).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pd.DataFrame(index=df['Heure'].unique())\n",
    "\n",
    "profile['PT_q1'] = df.loc[df['business_day'], [f'{feat}_q1', 'Heure']].groupby('Heure').median()\n",
    "profile['PT_q3'] = df.loc[df['business_day'], [f'{feat}_q3', 'Heure']].groupby('Heure').median()\n",
    "profile['PT_mean'] = df.loc[df['business_day'], [f'{feat}_mean', 'Heure']].groupby('Heure').median()\n",
    "\n",
    "df.loc[df['business_day'], 'PT_profile_q1'] = df['Heure'].apply(lambda x: profile.loc[x, 'PT_q1'])\n",
    "df.loc[df['business_day'], 'PT_profile_q3'] = df['Heure'].apply(lambda x: profile.loc[x, 'PT_q3'])\n",
    "df.loc[df['business_day'], 'PT_profile_mean'] = df['Heure'].apply(lambda x: profile.loc[x, 'PT_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_we = pd.DataFrame(index=df['Heure'].unique())\n",
    "\n",
    "profile_we['PT_q1'] = df.loc[~df['business_day'], [f'{feat}_q1', 'Heure']].groupby('Heure').median()\n",
    "profile_we['PT_q3'] = df.loc[~df['business_day'], [f'{feat}_q3', 'Heure']].groupby('Heure').median()\n",
    "profile_we['PT_mean'] = df.loc[~df['business_day'], [f'{feat}_mean', 'Heure']].groupby('Heure').median()\n",
    "\n",
    "df.loc[~df['business_day'], 'PT_profile_q1'] = df['Heure'].apply(lambda x: profile_we.loc[x, 'PT_q1'])\n",
    "df.loc[~df['business_day'], 'PT_profile_q3'] = df['Heure'].apply(lambda x: profile_we.loc[x, 'PT_q3'])\n",
    "df.loc[~df['business_day'], 'PT_profile_mean'] = df['Heure'].apply(lambda x: profile_we.loc[x, 'PT_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(df[['PT_profile_mean', 'business_day', 'PT (1 min)_mean']].resample('60T').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot['office'] = df_plot[['PT (1 min)_mean', 'PT_profile_mean']].min(axis=1)\n",
    "df_plot['min_smooth'] = df_plot[['PT (1 min)_mean', 'PT_profile_mean']].min(axis=1).rolling(30).quantile(.2)\n",
    "df_plot['baseline'] = df_plot[['min_smooth', 'PT (1 min)_mean', 'PT_profile_mean']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = 100*df_plot[['baseline', 'office', 'PT (1 min)_mean']].div(df_plot[['baseline', 'office', 'PT (1 min)_mean']].sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure([\n",
    "                    go.Scatter(x=df_plot.index, y=df_plot['baseline'], text=percentages['baseline'], name='Baseline', stackgroup='one', line_color='#636EFA', hovertemplate='%{text:.2f}%  (%{y:.2s}W)'),\n",
    "                    go.Scatter(x=df_plot.index, y=df_plot['office']-df_plot['baseline'], text=percentages['office'], name='Offices', stackgroup='one', line_color='#FFA15A', hovertemplate='%{text:.2f}%  (%{y:.2s}W)'),\n",
    "                    go.Scatter(x=df_plot.index, y=df_plot['PT (1 min)_mean']-df_plot['office'], text=percentages['PT (1 min)_mean'], name='Others', stackgroup='one', line_color='#00CC96', hovertemplate='%{text:.2f}%  (%{y:.2s}W)'),\n",
    "\n",
    "                    go.Scatter(x=df_plot.index, y=df_plot['office'], name='Offices', line_color='#FFA15A', showlegend=False, hoverinfo='skip'),\n",
    "                    go.Scatter(x=df_plot.index, y=df_plot['baseline'], name='Baseline', line_color='#636EFA', showlegend=False, hoverinfo='skip'),\n",
    "\n",
    "                ])\n",
    "\n",
    "fig.update_xaxes(showspikes=True, spikemode=\"across\", spikedash='solid', spikesnap='cursor', title='Temps')\n",
    "fig.update_yaxes(title='Puissance (W)')\n",
    "\n",
    "fig.update_layout(hovermode=\"x unified\", title='RÃ©partition de la puissance')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Data/df_profile.pkl')\n",
    "df_plot.to_pickle('Data/df_plot.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array\n",
    "data = df[['P1 (1 min)', 'P2 (1 min)', 'P3 (1 min)', 'Q1 (1 min)', 'Q2 (1 min)', 'Q3 (1 min)']].to_numpy()\n",
    "\n",
    "# Split the data into input and target sequences\n",
    "timesteps = 30  # Length of the input sequence\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data) - timesteps):\n",
    "    X.append(data[i:i+timesteps])\n",
    "    y.append(data[i+timesteps])\n",
    "X = np.array(X).astype(float)\n",
    "y = np.array(y).astype(float)\n",
    "\n",
    "# Standardize the data\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timeseries data\n",
    "\n",
    "# X.shape (41502, 10, 6)\n",
    "N_sample = X.shape[0]\n",
    "\n",
    "X_train, X_valid, X_test = X[:int(0.6*N_sample)], X[int(0.6*N_sample):int(0.8*N_sample)], X[int(0.8*N_sample):]\n",
    "\n",
    "# Set the parameters for the autoencoder\n",
    "latent_dim = 3  # Dimensionality of the latent space\n",
    "n_feat = X.shape[2]\n",
    "\n",
    "# Create the LSTM autoencoder model\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(LSTM(latent_dim, input_shape=(timesteps, n_feat), return_sequences=False, name='encode_LSTM'))\n",
    "model.add(RepeatVector(timesteps, name='Repeat'))\n",
    "\n",
    "# Decoder\n",
    "model.add(LSTM(n_feat, return_sequences=True, name='decode_LTSM'))\n",
    "model.add(TimeDistributed(Dense(n_feat), name='TD'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=False, validation_data=[X_valid, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs=model.inputs, outputs=model.layers[0].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index[-len(X_test):],y=components[:,0], name='component 1'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=df.index[-len(X_test):],y=components[:,1], name='component 1'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index[-len(X_test):], y=df['PT (1 min)'], name='PT'), row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Scatter(x=components[:,0], y=components[:,1], mode='markers'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "687660a6dde75a955fc59bd215d440460f417a5c942f0198eaf9051d894b46ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
